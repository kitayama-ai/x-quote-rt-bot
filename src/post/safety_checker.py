"""
X Auto Post System â€” å®‰å…¨ãƒã‚§ãƒƒã‚«ãƒ¼

æŠ•ç¨¿å‰ã«å®‰å…¨æ€§ã‚’æ¤œè¨¼ã€‚NGãƒ¯ãƒ¼ãƒ‰ã€æ–‡å­—æ•°ã€é‡è¤‡ã€æŠ•ç¨¿é–“éš”ã‚’ãƒã‚§ãƒƒã‚¯ã€‚
"""
import re
from dataclasses import dataclass, field
from difflib import SequenceMatcher


@dataclass
class SafetyResult:
    """å®‰å…¨ãƒã‚§ãƒƒã‚¯çµæœ"""
    is_safe: bool
    violations: list[str] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)

    def __str__(self) -> str:
        if self.is_safe:
            return "âœ… å®‰å…¨ãƒã‚§ãƒƒã‚¯é€šé"
        return f"âŒ å®‰å…¨ãƒã‚§ãƒƒã‚¯ä¸åˆæ ¼: {', '.join(self.violations)}"


class SafetyChecker:
    """æŠ•ç¨¿ã®å®‰å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""

    def __init__(self, safety_rules: dict):
        self.rules = safety_rules
        self._ng_words = []
        for category_words in safety_rules.get("ng_words", {}).values():
            self._ng_words.extend(category_words)

    def check(
        self,
        text: str,
        past_posts: list[str] | None = None,
        last_post_minutes_ago: int | None = None,
        is_quote_rt: bool = False,
        quote_rt_context: dict | None = None,
    ) -> SafetyResult:
        """
        å…¨å®‰å…¨ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ

        Args:
            text: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            past_posts: éå»ã®æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆï¼ˆé‡è¤‡æ¤œå‡ºç”¨ï¼‰
            last_post_minutes_ago: å‰å›æŠ•ç¨¿ã‹ã‚‰ã®çµŒéåˆ†æ•°
            is_quote_rt: å¼•ç”¨RTæŠ•ç¨¿ã‹ã©ã†ã‹
            quote_rt_context: å¼•ç”¨RTè¿½åŠ æƒ…å ± {
                "source_username": str,
                "today_same_source_count": int,
                "consecutive_quote_count": int,
            }
        """
        violations = []
        warnings = []

        # 1. NGãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        ng_found = self._check_ng_words(text)
        if ng_found:
            violations.append(f"NGãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: {', '.join(ng_found)}")

        # 2. æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
        content_rules = self.rules.get("content_rules", {})
        text_len = len(text.replace('\n', ''))

        if is_quote_rt:
            # å¼•ç”¨RTã¯çŸ­ã‚ï¼ˆURLåˆ†ã‚’è€ƒæ…®ï¼‰
            min_len = 30
            max_len = 250
        else:
            min_len = content_rules.get("min_length", 40)
            max_len = content_rules.get("max_length", 280)

        if text_len < min_len:
            violations.append(f"æ–‡å­—æ•°ä¸è¶³: {text_len}å­— (æœ€ä½{min_len}å­—)")
        if text_len > max_len:
            violations.append(f"æ–‡å­—æ•°è¶…é: {text_len}å­— (æœ€å¤§{max_len}å­—)")

        # 3. ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°æ•°ãƒã‚§ãƒƒã‚¯
        max_hashtags = content_rules.get("max_hashtags", 3)
        hashtags = re.findall(r'#\S+', text)
        if len(hashtags) > max_hashtags:
            violations.append(f"ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°éå¤š: {len(hashtags)}å€‹ (æœ€å¤§{max_hashtags}å€‹)")

        # 4. ãƒªãƒ³ã‚¯æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆå¼•ç”¨RTã¯URLä¸è¦ã€APIãŒä»˜ä¸ï¼‰
        if is_quote_rt:
            links = re.findall(r'https?://\S+', text)
            if len(links) > 0:
                warnings.append("å¼•ç”¨RTã‚³ãƒ¡ãƒ³ãƒˆã«URLä¸è¦ï¼ˆAPIãŒè‡ªå‹•ä»˜ä¸ï¼‰")
        else:
            max_links = content_rules.get("max_links", 1)
            links = re.findall(r'https?://\S+', text)
            if len(links) > max_links:
                violations.append(f"ãƒªãƒ³ã‚¯éå¤š: {len(links)}å€‹ (æœ€å¤§{max_links}å€‹)")

        # 5. çµµæ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
        max_emoji = content_rules.get("max_emoji", 3)
        emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map symbols
            "\U0001F1E0-\U0001F1FF"  # flags
            "\U00002702-\U000027B0"  # dingbats
            "\U0001F900-\U0001F9FF"  # supplemental symbols
            "\U0001FA00-\U0001FA6F"  # chess symbols
            "\U0001FA70-\U0001FAFF"  # symbols extended-A
            "\U00002600-\U000026FF"  # misc symbols
            "\U0000FE00-\U0000FE0F"  # variation selectors
            "\U0000200D"             # zero width joiner
            "]",
            flags=re.UNICODE
        )
        emojis = emoji_pattern.findall(text)
        emoji_count = len(emojis)
        if emoji_count > max_emoji:
            warnings.append(f"çµµæ–‡å­—{emoji_count}å€‹ (æ¨å¥¨{max_emoji}å€‹ä»¥ä¸‹)")

        # 6. é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if past_posts:
            threshold = self.rules.get("quality_rules", {}).get("duplicate_threshold", 0.8)
            for past in past_posts:
                similarity = SequenceMatcher(None, text, past).ratio()
                if similarity >= threshold:
                    violations.append(
                        f"éå»æŠ•ç¨¿ã¨é¡ä¼¼åº¦{similarity:.0%} (é–¾å€¤{threshold:.0%})"
                    )
                    break

        # 7. æŠ•ç¨¿é–“éš”ãƒã‚§ãƒƒã‚¯ï¼ˆ10æŠ•ç¨¿å¯¾å¿œ: 60åˆ†é–“éš”ï¼‰
        if last_post_minutes_ago is not None:
            min_interval = self.rules.get("posting_rules", {}).get(
                "posting_interval_min_minutes", 60
            )
            if last_post_minutes_ago < min_interval:
                violations.append(
                    f"æŠ•ç¨¿é–“éš”ä¸è¶³: {last_post_minutes_ago}åˆ† (æœ€ä½{min_interval}åˆ†)"
                )

        # 8. å¼•ç”¨RTå°‚ç”¨ãƒã‚§ãƒƒã‚¯
        if is_quote_rt and quote_rt_context:
            qt_violations, qt_warnings = self._check_quote_rt(text, quote_rt_context)
            violations.extend(qt_violations)
            warnings.extend(qt_warnings)

        is_safe = len(violations) == 0
        return SafetyResult(is_safe=is_safe, violations=violations, warnings=warnings)

    def _check_quote_rt(self, text: str, context: dict) -> tuple[list[str], list[str]]:
        """å¼•ç”¨RTå°‚ç”¨ã®å®‰å…¨ãƒã‚§ãƒƒã‚¯"""
        violations = []
        warnings = []

        # åŒä¸€ã‚½ãƒ¼ã‚¹ã®1æ—¥åˆ¶é™
        max_same_source = 1
        if context.get("today_same_source_count", 0) >= max_same_source:
            violations.append(
                f"åŒä¸€ã‚½ãƒ¼ã‚¹å¼•ç”¨ãŒ1æ—¥{max_same_source}ä»¶ã‚’è¶…é "
                f"(@{context.get('source_username', '?')})"
            )

        # é€£ç¶šå¼•ç”¨RTåˆ¶é™
        max_consecutive = 2
        if context.get("consecutive_quote_count", 0) >= max_consecutive:
            warnings.append(
                f"å¼•ç”¨RTãŒ{max_consecutive}ä»¶é€£ç¶šã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«æŠ•ç¨¿ã‚’æŒŸã‚€ã“ã¨ã‚’æ¨å¥¨"
            )

        # ç¿»è¨³ã ã‘æŠ•ç¨¿ã®æ¤œå‡ºï¼ˆç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        banned = ["ç¿»è¨³ã—ã¾ã—ãŸ", "Translation:", "translated"]
        for pattern in banned:
            if pattern.lower() in text.lower():
                violations.append(f"ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º: '{pattern}' â€” ç‹¬è‡ªã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
                break

        return violations, warnings

    def _check_ng_words(self, text: str) -> list[str]:
        """NGãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡º"""
        text_lower = text.lower()
        found = []
        for word in self._ng_words:
            if word.lower() in text_lower:
                found.append(word)
        return found

    def format_result(self, result: SafetyResult) -> str:
        """çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        lines = []
        if result.is_safe:
            lines.append("ğŸ›¡ï¸ å®‰å…¨ãƒã‚§ãƒƒã‚¯: âœ… PASS")
        else:
            lines.append("ğŸ›¡ï¸ å®‰å…¨ãƒã‚§ãƒƒã‚¯: âŒ FAIL")
            for v in result.violations:
                lines.append(f"  â›” {v}")
        for w in result.warnings:
            lines.append(f"  âš ï¸ {w}")
        return '\n'.join(lines)
